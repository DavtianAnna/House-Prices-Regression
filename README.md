# ğŸ  House Prices - Kaggle Regression Challenge

This repository contains my solution for the [House Prices - Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques) competition on Kaggle.
The goal is to predict the final sale price of residential homes in Ames, Iowa using advanced regression models based on 79 explanatory variables.

![Chesterwell_StreetScenes_Additional_MerseaHomes-25-of-31-CHESTERWELL-GROVE-1](https://github.com/user-attachments/assets/5f19550b-d512-4128-aa8e-5a21fa21a6bd)


---

## ğŸ—‚ï¸ Project Structure
```

project-root/
â”œâ”€â”€ ğŸ§  task.ipynb               # Main notebook: full ML pipeline from preprocessing to model predictions
â”œâ”€â”€ ğŸ“Š train.csv                # Training data with house features and SalePrice
â”œâ”€â”€ ğŸ§ª test.csv                 # Test data for prediction
â”œâ”€â”€ ğŸ“ sample_submission.csv    # Submission format
â”œâ”€â”€ ğŸš€ submission.csv           # Submission from LinearRegression
â”œâ”€â”€ ğŸš€ submission1.csv          # Submission from SGDRegressor
â”œâ”€â”€ ğŸš€ submission2.csv          # Submission from RandomForestRegressor
â””â”€â”€ ğŸ“œ README.md                # Project documentation

```

---

## ğŸ’» Technologies Used

- **Language**: Python 3.x  
- **Environment**: Jupyter Notebook

## ğŸ“¦ Libraries

- `numpy`, `pandas` â€“ Data manipulation  
- `matplotlib`, `seaborn` â€“ Visualization  
- `scikit-learn` â€“ Modeling, preprocessing, evaluation  
- `warnings` â€“ Suppress warning messages

---

## ğŸ“Š Dataset Description

Competition: [House Prices â€“ Advanced Regression Techniques](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)

- `train.csv`: Training data, includes features + target column `SalePrice`
- `test.csv`: Test data without target, used for submission
- `sample_submission.csv`: Format required for Kaggle submission

---

## ğŸ” Workflow Summary

The `task.ipynb` notebook implements the following steps:

### 1. ğŸ“¥ Data Loading & Cleaning
- Loaded training and test datasets using `pandas`.
- Dropped columns with high missing values:
  - `'MiscFeature'`, `'Alley'`, `'Fence'`, `'MasVnrType'`, `'FireplaceQu'`, `'PoolQC'`
- Filled missing values:
  - Fixed values (e.g. `LotFrontage = 60`, `GarageYrBlt = 2005`)
  - Categorical values (e.g. `'GarageCond' = 'TA'`, `'GarageFinish'` = random from valid categories)
- Used `LabelEncoder` for categorical encoding (`object` type columns)


### 2. ğŸ§  Modeling & Tuning

| Model                  | Tuning Method         | Output File       |
|------------------------|-----------------------|-------------------|
| `LinearRegression`     | None                  | `submission.csv`  |
| `SGDRegressor`         | Pipeline + GridSearchCV | `submission1.csv` |
| `RandomForestRegressor`| Default parameters    | `submission2.csv` |


### 3. ğŸ“¤ Prediction & Submission

Final predictions were made on the test dataset and saved as:

- `submission.csv` â†’ from Linear Regression  
- `submission1.csv` â†’ from SGD Regressor  
- `submission2.csv` â†’ from Random Forest Regressor

---


## ğŸ“ˆ Next Improvements

- Feature engineering: polynomial features, interaction terms  
- Log transformation of skewed data  
- Model ensembling (stacking or blending)  
- Outlier removal for improved model robustness

---

## âš™ï¸ Installation

To install required libraries:


